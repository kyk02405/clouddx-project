"""
============================================
Indexer Consumer - Elasticsearch ì¸ë±ì‹±
============================================

Kafka 'news' í† í”½ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ì—¬
Elasticsearchì— ì¸ë±ì‹±í•©ë‹ˆë‹¤.

ìš´ì˜ í™˜ê²½: Node3ì—ì„œ ì‹¤í–‰
í† í”½: news
ES í˜¸ìŠ¤íŠ¸: Node3 (í˜¸ìŠ¤íŠ¸ ì„¤ì¹˜)
"""

import asyncio
import json
import os
from datetime import datetime

from aiokafka import AIOKafkaConsumer
from elasticsearch import AsyncElasticsearch

KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
TOPIC = "news"
GROUP_ID = "indexer-consumer-group"
INDEX_NAME = "news"


async def ensure_index(es: AsyncElasticsearch):
    """ë‰´ìŠ¤ ì¸ë±ìŠ¤ ìƒì„± (ì—†ëŠ” ê²½ìš°)"""
    if not await es.indices.exists(index=INDEX_NAME):
        await es.indices.create(
            index=INDEX_NAME,
            body={
                "mappings": {
                    "properties": {
                        "title": {"type": "text", "analyzer": "standard"},
                        "content": {"type": "text", "analyzer": "standard"},
                        "summary": {"type": "text", "analyzer": "standard"},
                        "source": {"type": "keyword"},
                        "url": {"type": "keyword"},
                        "published_at": {"type": "date"},
                        "indexed_at": {"type": "date"},
                        "tags": {"type": "keyword"},
                        "related_assets": {"type": "keyword"}
                    }
                }
            }
        )
        print(f"âœ… ì¸ë±ìŠ¤ ìƒì„±: {INDEX_NAME}")


async def main():
    """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
    print(f"ğŸš€ Indexer Consumer ì‹œì‘")
    print(f"   Kafka: {KAFKA_BOOTSTRAP_SERVERS}")
    print(f"   Elasticsearch: {ELASTICSEARCH_URL}")
    
    # Elasticsearch ì—°ê²°
    es = AsyncElasticsearch(hosts=[ELASTICSEARCH_URL])
    await ensure_index(es)
    
    # Kafka Consumer ì—°ê²°
    consumer = AIOKafkaConsumer(
        TOPIC,
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        group_id=GROUP_ID,
        value_deserializer=lambda v: json.loads(v.decode('utf-8'))
    )
    
    await consumer.start()
    print(f"âœ… Kafka ì—°ê²° ì„±ê³µ, í† í”½: {TOPIC}, ê·¸ë£¹: {GROUP_ID}")
    
    try:
        async for message in consumer:
            news_data = message.value
            
            # ì¸ë±ì‹±í•  ë¬¸ì„œ ì¤€ë¹„
            doc = {
                **news_data,
                "indexed_at": datetime.utcnow().isoformat()
            }
            
            # Elasticsearchì— ì¸ë±ì‹±
            result = await es.index(index=INDEX_NAME, document=doc)
            print(f"ğŸ“¥ ì¸ë±ì‹± ì™„ë£Œ: {news_data['title'][:30]}... (ID: {result['_id']})")
            
    except KeyboardInterrupt:
        print("ì¢…ë£Œ ìš”ì²­")
    finally:
        await consumer.stop()
        await es.close()
        print("Consumer ì¢…ë£Œ")


if __name__ == "__main__":
    asyncio.run(main())
